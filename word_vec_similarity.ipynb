{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled7.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPx4iPSMayNM2ko1L4P7gyJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yashugupta786/word_vec_similarity/blob/master/word_vec_similarity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqX7as_5L9Dw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re  # For preprocessing\n",
        "import pandas as pd  # For data handling\n",
        "from time import time  # To time our operations\n",
        "from collections import defaultdict  # For word frequency\n",
        "\n",
        "import spacy  # For preprocessing\n",
        "\n",
        "import logging  # Setting up the loggings to monitor gensim\n",
        "logging.basicConfig(format=\"%(levelname)s - %(asctime)s: %(message)s\", datefmt= '%H:%M:%S', level=logging.INFO)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGwGzXJWXWAL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLb2Ul_NMuJn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dabf6b72-bc77-4256-bc18-8b848f07ffe8"
      },
      "source": [
        "df = pd.read_csv('/content/simpsons_dataset.csv')\n",
        "df.shape"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(158314, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxrGKx6bMzdi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "3e390c0e-6be2-4d38-bc0e-c20fbf270051"
      },
      "source": [
        "df = df.dropna().reset_index(drop=True)\n",
        "df.isnull().sum()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "raw_character_text    0\n",
              "spoken_words          0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2aRT0dXM63e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nlp = spacy.load('en', disable=['ner', 'parser']) # disabling Named Entity Recognition for speed\n",
        "\n",
        "def cleaning(doc):\n",
        "    # Lemmatizes and removes stopwords\n",
        "    # doc needs to be a spacy Doc object\n",
        "    txt = [token.lemma_ for token in doc if not token.is_stop]\n",
        "    # Word2Vec uses context words to learn the vector representation of a target word,\n",
        "    # if a sentence is only one or two words long,\n",
        "    # the benefit for the training is very small\n",
        "    if len(txt) > 2:\n",
        "        return ' '.join(txt)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krqujn2GM9wV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "brief_cleaning = (re.sub(\"[^A-Za-z']+\", ' ', str(row)).lower() for row in df['spoken_words'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t06W9dWkNBWs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "45e06906-b3ab-423e-d3c7-d4ddb4fcf250"
      },
      "source": [
        "t = time()\n",
        "\n",
        "txt = [cleaning(doc) for doc in nlp.pipe(brief_cleaning, batch_size=5000, n_threads=-1)]\n",
        "\n",
        "print('Time to clean up everything: {} mins'.format(round((time() - t) / 60, 2)))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time to clean up everything: 0.96 mins\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bS8e0YWnNGOh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b707e3e7-9511-43e9-c8c8-eb7cd1e0e2fd"
      },
      "source": [
        "df_clean = pd.DataFrame({'clean': txt})\n",
        "df_clean = df_clean.dropna().drop_duplicates()\n",
        "df_clean.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(85964, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjgg6QA4NMkj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "fe7c3567-65c4-474a-cb58-046d432a9fd7"
      },
      "source": [
        "df_clean.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>clean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>actually little disease magazine news show nat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>know sure like talk touch lesson plan teach</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>life worth live</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>poll open end recess case decide thought final...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>victory party slide</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               clean\n",
              "0  actually little disease magazine news show nat...\n",
              "2        know sure like talk touch lesson plan teach\n",
              "3                                    life worth live\n",
              "4  poll open end recess case decide thought final...\n",
              "7                                victory party slide"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXVi1GBFNY0t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "edfdfaf8-69af-4f2d-f17f-bf882b5b3873"
      },
      "source": [
        "from gensim.models.phrases import Phrases, Phraser"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO - 08:01:43: 'pattern' package not found; tag filters are not available for English\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JuTSlxXNcJ5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sent = [row.split() for row in df_clean['clean']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZeEzeGPNfvk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "6bfe4125-8222-476c-f161-c56635d3da4b"
      },
      "source": [
        "phrases = Phrases(sent, min_count=30, progress_per=10000)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO - 08:02:09: collecting all words and their counts\n",
            "INFO - 08:02:09: PROGRESS: at sentence #0, processed 0 words and 0 word types\n",
            "INFO - 08:02:09: PROGRESS: at sentence #10000, processed 63561 words and 52816 word types\n",
            "INFO - 08:02:10: PROGRESS: at sentence #20000, processed 130943 words and 99866 word types\n",
            "INFO - 08:02:10: PROGRESS: at sentence #30000, processed 192972 words and 138532 word types\n",
            "INFO - 08:02:10: PROGRESS: at sentence #40000, processed 249842 words and 172659 word types\n",
            "INFO - 08:02:10: PROGRESS: at sentence #50000, processed 311265 words and 208566 word types\n",
            "INFO - 08:02:10: PROGRESS: at sentence #60000, processed 373588 words and 243702 word types\n",
            "INFO - 08:02:10: PROGRESS: at sentence #70000, processed 436441 words and 278740 word types\n",
            "INFO - 08:02:10: PROGRESS: at sentence #80000, processed 497829 words and 311886 word types\n",
            "INFO - 08:02:10: collected 330804 word types from a corpus of 537160 words (unigram + bigrams) and 85964 sentences\n",
            "INFO - 08:02:10: using 330804 counts as vocab in Phrases<0 vocab, min_count=30, threshold=10.0, max_vocab_size=40000000>\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ixJwu0MNiwY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "9d90f66b-81bf-4d6a-a434-ceac45d0d80c"
      },
      "source": [
        "bigram = Phraser(phrases)\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO - 08:02:55: source_vocab length 330804\n",
            "INFO - 08:02:58: Phraser built with 126 phrasegrams\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ruOZI0CNoa8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences = bigram[sent]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FPKXXjCNx7b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences\n",
        "for i in sentences:\n",
        "  print(i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsbqesTyNzOL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8742839d-5574-49d4-a01c-756b15faded9"
      },
      "source": [
        "word_freq = defaultdict(int)\n",
        "for sent in sentences:\n",
        "    for i in sent:\n",
        "        word_freq[i] += 1\n",
        "len(word_freq)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30178"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vG-uJuAYN2ir",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9a6beff0-9f01-4a55-bf82-c75cfcedd19f"
      },
      "source": [
        "sorted(word_freq, key=word_freq.get, reverse=True)[:10]"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['oh', 'like', 'know', 'get', 'hey', 'think', 'right', 'look', 'want', 'come']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PaldJi3xN42B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import multiprocessing\n",
        "\n",
        "from gensim.models import Word2Vec"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VT4onw2CN8dN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "w2v_model = Word2Vec(min_count=20,\n",
        "                     window=2,\n",
        "                     size=300,\n",
        "                     sample=6e-5, \n",
        "                     alpha=0.03, \n",
        "                     min_alpha=0.0007, \n",
        "                     negative=20,\n",
        "                  )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jDd6-zVPJJ8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "331a1b5b-22cf-4a7a-85b6-6d1736321f1d"
      },
      "source": [
        "t = time()\n",
        "\n",
        "w2v_model.build_vocab(sentences, progress_per=10000)\n",
        "\n",
        "print('Time to build vocab: {} mins'.format(round((time() - t) / 60, 2)))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO - 08:09:41: collecting all words and their counts\n",
            "INFO - 08:09:41: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
            "INFO - 08:09:41: PROGRESS: at sentence #10000, processed 61718 words, keeping 9558 word types\n",
            "INFO - 08:09:41: PROGRESS: at sentence #20000, processed 127351 words, keeping 14506 word types\n",
            "INFO - 08:09:41: PROGRESS: at sentence #30000, processed 187829 words, keeping 17619 word types\n",
            "INFO - 08:09:42: PROGRESS: at sentence #40000, processed 243332 words, keeping 20385 word types\n",
            "INFO - 08:09:42: PROGRESS: at sentence #50000, processed 303182 words, keeping 22878 word types\n",
            "INFO - 08:09:42: PROGRESS: at sentence #60000, processed 363940 words, keeping 25200 word types\n",
            "INFO - 08:09:42: PROGRESS: at sentence #70000, processed 425408 words, keeping 27401 word types\n",
            "INFO - 08:09:42: PROGRESS: at sentence #80000, processed 485464 words, keeping 29275 word types\n",
            "INFO - 08:09:42: collected 30178 word types from a corpus of 523700 raw words and 85964 sentences\n",
            "INFO - 08:09:42: Loading a fresh vocabulary\n",
            "INFO - 08:09:42: effective_min_count=20 retains 3319 unique words (10% of original 30178, drops 26859)\n",
            "INFO - 08:09:43: effective_min_count=20 leaves 437324 word corpus (83% of original 523700, drops 86376)\n",
            "INFO - 08:09:43: deleting the raw counts dictionary of 30178 items\n",
            "INFO - 08:09:43: sample=6e-05 downsamples 1200 most-common words\n",
            "INFO - 08:09:43: downsampling leaves estimated 199161 word corpus (45.5% of prior 437324)\n",
            "INFO - 08:09:43: estimated required memory for 3319 words and 300 dimensions: 9625100 bytes\n",
            "INFO - 08:09:43: resetting layer weights\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time to build vocab: 0.04 mins\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHVQsuqqPQ_j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9c0a4ac7-eb67-4f2e-96a4-0f22974f2e8d"
      },
      "source": [
        "t = time()\n",
        "\n",
        "w2v_model.train(sentences, total_examples=w2v_model.corpus_count, epochs=30, report_delay=1)\n",
        "\n",
        "print('Time to train the model: {} mins'.format(round((time() - t) / 60, 2)))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO - 08:10:03: training model with 3 workers on 3319 vocabulary and 300 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 08:10:04: EPOCH 1 - PROGRESS: at 37.40% examples, 74816 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 08:10:05: EPOCH 1 - PROGRESS: at 78.53% examples, 76880 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 08:10:06: worker thread finished; awaiting finish of 2 more threads\n",
            "INFO - 08:10:06: worker thread finished; awaiting finish of 1 more threads\n",
            "INFO - 08:10:06: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 08:10:06: EPOCH - 1 : training on 523700 raw words (198820 effective words) took 2.6s, 77786 effective words/s\n",
            "INFO - 08:10:07: EPOCH 2 - PROGRESS: at 37.40% examples, 75235 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 08:10:08: EPOCH 2 - PROGRESS: at 74.71% examples, 72498 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 08:10:09: worker thread finished; awaiting finish of 2 more threads\n",
            "INFO - 08:10:09: worker thread finished; awaiting finish of 1 more threads\n",
            "INFO - 08:10:09: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 08:10:09: EPOCH - 2 : training on 523700 raw words (199218 effective words) took 2.7s, 73992 effective words/s\n",
            "INFO - 08:10:10: EPOCH 3 - PROGRESS: at 39.38% examples, 76556 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 08:10:11: EPOCH 3 - PROGRESS: at 80.39% examples, 76031 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 08:10:11: worker thread finished; awaiting finish of 2 more threads\n",
            "INFO - 08:10:11: worker thread finished; awaiting finish of 1 more threads\n",
            "INFO - 08:10:11: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 08:10:11: EPOCH - 3 : training on 523700 raw words (199222 effective words) took 2.6s, 77085 effective words/s\n",
            "INFO - 08:10:12: EPOCH 4 - PROGRESS: at 35.34% examples, 70104 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 08:10:13: EPOCH 4 - PROGRESS: at 74.71% examples, 72946 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 08:10:14: worker thread finished; awaiting finish of 2 more threads\n",
            "INFO - 08:10:14: worker thread finished; awaiting finish of 1 more threads\n",
            "INFO - 08:10:14: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 08:10:14: EPOCH - 4 : training on 523700 raw words (199150 effective words) took 2.7s, 74361 effective words/s\n",
            "INFO - 08:10:15: EPOCH 5 - PROGRESS: at 37.40% examples, 73743 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 08:10:16: EPOCH 5 - PROGRESS: at 76.60% examples, 75082 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 08:10:17: worker thread finished; awaiting finish of 2 more threads\n",
            "INFO - 08:10:17: worker thread finished; awaiting finish of 1 more threads\n",
            "INFO - 08:10:17: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 08:10:17: EPOCH - 5 : training on 523700 raw words (199540 effective words) took 2.7s, 73753 effective words/s\n",
            "INFO - 08:10:18: EPOCH 6 - PROGRESS: at 39.38% examples, 74335 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 08:10:19: EPOCH 6 - PROGRESS: at 82.28% examples, 76525 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 08:10:19: worker thread finished; awaiting finish of 2 more threads\n",
            "INFO - 08:10:19: worker thread finished; awaiting finish of 1 more threads\n",
            "INFO - 08:10:19: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 08:10:19: EPOCH - 6 : training on 523700 raw words (199462 effective words) took 2.6s, 77777 effective words/s\n",
            "INFO - 08:10:20: EPOCH 7 - PROGRESS: at 37.40% examples, 75474 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 08:10:21: EPOCH 7 - PROGRESS: at 72.83% examples, 71991 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 08:10:22: worker thread finished; awaiting finish of 2 more threads\n",
            "INFO - 08:10:22: worker thread finished; awaiting finish of 1 more threads\n",
            "INFO - 08:10:22: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 08:10:22: EPOCH - 7 : training on 523700 raw words (199000 effective words) took 2.7s, 73722 effective words/s\n",
            "INFO - 08:10:23: EPOCH 8 - PROGRESS: at 37.40% examples, 74112 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 08:10:24: EPOCH 8 - PROGRESS: at 76.60% examples, 73551 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 08:10:25: worker thread finished; awaiting finish of 2 more threads\n",
            "INFO - 08:10:25: worker thread finished; awaiting finish of 1 more threads\n",
            "INFO - 08:10:25: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 08:10:25: EPOCH - 8 : training on 523700 raw words (199266 effective words) took 2.7s, 74917 effective words/s\n",
            "INFO - 08:10:26: EPOCH 9 - PROGRESS: at 35.34% examples, 68356 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 08:10:27: EPOCH 9 - PROGRESS: at 74.71% examples, 71752 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 08:10:27: worker thread finished; awaiting finish of 2 more threads\n",
            "INFO - 08:10:27: worker thread finished; awaiting finish of 1 more threads\n",
            "INFO - 08:10:27: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 08:10:27: EPOCH - 9 : training on 523700 raw words (199201 effective words) took 2.7s, 73832 effective words/s\n",
            "INFO - 08:10:28: EPOCH 10 - PROGRESS: at 37.40% examples, 75005 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 08:10:29: EPOCH 10 - PROGRESS: at 78.53% examples, 76513 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 08:10:30: worker thread finished; awaiting finish of 2 more threads\n",
            "INFO - 08:10:30: worker thread finished; awaiting finish of 1 more threads\n",
            "INFO - 08:10:30: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 08:10:30: EPOCH - 10 : training on 523700 raw words (199075 effective words) took 2.6s, 76618 effective words/s\n",
            "INFO - 08:10:31: EPOCH 11 - PROGRESS: at 33.37% examples, 68079 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 08:10:32: EPOCH 11 - PROGRESS: at 72.83% examples, 71926 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 08:10:33: worker thread finished; awaiting finish of 2 more threads\n",
            "INFO - 08:10:33: worker thread finished; awaiting finish of 1 more threads\n",
            "INFO - 08:10:33: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 08:10:33: EPOCH - 11 : training on 523700 raw words (199385 effective words) took 2.7s, 74194 effective words/s\n",
            "INFO - 08:10:34: EPOCH 12 - PROGRESS: at 37.40% examples, 75435 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 08:10:35: EPOCH 12 - PROGRESS: at 72.83% examples, 71906 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 08:10:35: worker thread finished; awaiting finish of 2 more threads\n",
            "INFO - 08:10:35: worker thread finished; awaiting finish of 1 more threads\n",
            "INFO - 08:10:35: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 08:10:35: EPOCH - 12 : training on 523700 raw words (198819 effective words) took 2.7s, 73780 effective words/s\n",
            "INFO - 08:10:36: EPOCH 13 - PROGRESS: at 37.40% examples, 75280 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 08:10:37: EPOCH 13 - PROGRESS: at 76.60% examples, 75691 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 08:10:38: worker thread finished; awaiting finish of 2 more threads\n",
            "INFO - 08:10:38: worker thread finished; awaiting finish of 1 more threads\n",
            "INFO - 08:10:38: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 08:10:38: EPOCH - 13 : training on 523700 raw words (199107 effective words) took 2.6s, 76257 effective words/s\n",
            "INFO - 08:10:39: EPOCH 14 - PROGRESS: at 33.37% examples, 67588 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 08:10:40: EPOCH 14 - PROGRESS: at 72.83% examples, 71968 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 08:10:41: worker thread finished; awaiting finish of 2 more threads\n",
            "INFO - 08:10:41: worker thread finished; awaiting finish of 1 more threads\n",
            "INFO - 08:10:41: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 08:10:41: EPOCH - 14 : training on 523700 raw words (199018 effective words) took 2.7s, 73593 effective words/s\n",
            "INFO - 08:10:42: EPOCH 15 - PROGRESS: at 37.40% examples, 74915 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 08:10:43: EPOCH 15 - PROGRESS: at 76.60% examples, 75043 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 08:10:43: worker thread finished; awaiting finish of 2 more threads\n",
            "INFO - 08:10:43: worker thread finished; awaiting finish of 1 more threads\n",
            "INFO - 08:10:43: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 08:10:43: EPOCH - 15 : training on 523700 raw words (199635 effective words) took 2.7s, 73326 effective words/s\n",
            "INFO - 08:10:44: EPOCH 16 - PROGRESS: at 37.40% examples, 74604 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 08:10:45: EPOCH 16 - PROGRESS: at 78.53% examples, 76751 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 08:10:46: worker thread finished; awaiting finish of 2 more threads\n",
            "INFO - 08:10:46: worker thread finished; awaiting finish of 1 more threads\n",
            "INFO - 08:10:46: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 08:10:46: EPOCH - 16 : training on 523700 raw words (199205 effective words) took 2.6s, 76956 effective words/s\n",
            "INFO - 08:10:47: EPOCH 17 - PROGRESS: at 37.40% examples, 73137 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 08:10:48: EPOCH 17 - PROGRESS: at 74.71% examples, 72777 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 08:10:49: worker thread finished; awaiting finish of 2 more threads\n",
            "INFO - 08:10:49: worker thread finished; awaiting finish of 1 more threads\n",
            "INFO - 08:10:49: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 08:10:49: EPOCH - 17 : training on 523700 raw words (199196 effective words) took 2.7s, 74120 effective words/s\n",
            "INFO - 08:10:50: EPOCH 18 - PROGRESS: at 37.40% examples, 73697 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 08:10:51: EPOCH 18 - PROGRESS: at 78.53% examples, 75961 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 08:10:51: worker thread finished; awaiting finish of 2 more threads\n",
            "INFO - 08:10:51: worker thread finished; awaiting finish of 1 more threads\n",
            "INFO - 08:10:51: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 08:10:51: EPOCH - 18 : training on 523700 raw words (199097 effective words) took 2.6s, 76522 effective words/s\n",
            "INFO - 08:10:52: EPOCH 19 - PROGRESS: at 33.37% examples, 67781 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 08:10:53: EPOCH 19 - PROGRESS: at 72.83% examples, 72070 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 08:10:54: worker thread finished; awaiting finish of 2 more threads\n",
            "INFO - 08:10:54: worker thread finished; awaiting finish of 1 more threads\n",
            "INFO - 08:10:54: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 08:10:54: EPOCH - 19 : training on 523700 raw words (199697 effective words) took 2.7s, 74412 effective words/s\n",
            "INFO - 08:10:55: EPOCH 20 - PROGRESS: at 37.40% examples, 75438 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 08:10:56: EPOCH 20 - PROGRESS: at 76.60% examples, 74821 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 08:10:57: worker thread finished; awaiting finish of 2 more threads\n",
            "INFO - 08:10:57: worker thread finished; awaiting finish of 1 more threads\n",
            "INFO - 08:10:57: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 08:10:57: EPOCH - 20 : training on 523700 raw words (199491 effective words) took 2.7s, 74579 effective words/s\n",
            "INFO - 08:10:58: EPOCH 21 - PROGRESS: at 33.37% examples, 66531 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 08:10:59: EPOCH 21 - PROGRESS: at 72.83% examples, 70811 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 08:10:59: worker thread finished; awaiting finish of 2 more threads\n",
            "INFO - 08:10:59: worker thread finished; awaiting finish of 1 more threads\n",
            "INFO - 08:10:59: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 08:10:59: EPOCH - 21 : training on 523700 raw words (198582 effective words) took 2.7s, 73650 effective words/s\n",
            "INFO - 08:11:00: EPOCH 22 - PROGRESS: at 37.40% examples, 73519 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 08:11:01: EPOCH 22 - PROGRESS: at 78.53% examples, 74721 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 08:11:02: worker thread finished; awaiting finish of 2 more threads\n",
            "INFO - 08:11:02: worker thread finished; awaiting finish of 1 more threads\n",
            "INFO - 08:11:02: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 08:11:02: EPOCH - 22 : training on 523700 raw words (199255 effective words) took 2.6s, 75946 effective words/s\n",
            "INFO - 08:11:03: EPOCH 23 - PROGRESS: at 33.37% examples, 67009 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 08:11:04: EPOCH 23 - PROGRESS: at 72.83% examples, 71340 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 08:11:05: worker thread finished; awaiting finish of 2 more threads\n",
            "INFO - 08:11:05: worker thread finished; awaiting finish of 1 more threads\n",
            "INFO - 08:11:05: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 08:11:05: EPOCH - 23 : training on 523700 raw words (199012 effective words) took 2.7s, 73282 effective words/s\n",
            "INFO - 08:11:06: EPOCH 24 - PROGRESS: at 37.40% examples, 75209 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 08:11:07: EPOCH 24 - PROGRESS: at 74.71% examples, 72707 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 08:11:07: worker thread finished; awaiting finish of 2 more threads\n",
            "INFO - 08:11:07: worker thread finished; awaiting finish of 1 more threads\n",
            "INFO - 08:11:07: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 08:11:07: EPOCH - 24 : training on 523700 raw words (198827 effective words) took 2.7s, 74128 effective words/s\n",
            "INFO - 08:11:09: EPOCH 25 - PROGRESS: at 39.38% examples, 74735 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 08:11:10: EPOCH 25 - PROGRESS: at 80.39% examples, 76168 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 08:11:10: worker thread finished; awaiting finish of 2 more threads\n",
            "INFO - 08:11:10: worker thread finished; awaiting finish of 1 more threads\n",
            "INFO - 08:11:10: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 08:11:10: EPOCH - 25 : training on 523700 raw words (199315 effective words) took 2.6s, 77005 effective words/s\n",
            "INFO - 08:11:11: EPOCH 26 - PROGRESS: at 35.34% examples, 71093 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 08:11:12: EPOCH 26 - PROGRESS: at 74.71% examples, 72417 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 08:11:13: worker thread finished; awaiting finish of 2 more threads\n",
            "INFO - 08:11:13: worker thread finished; awaiting finish of 1 more threads\n",
            "INFO - 08:11:13: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 08:11:13: EPOCH - 26 : training on 523700 raw words (199170 effective words) took 2.7s, 74304 effective words/s\n",
            "INFO - 08:11:14: EPOCH 27 - PROGRESS: at 35.34% examples, 71347 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 08:11:15: EPOCH 27 - PROGRESS: at 74.71% examples, 73467 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 08:11:15: worker thread finished; awaiting finish of 2 more threads\n",
            "INFO - 08:11:15: worker thread finished; awaiting finish of 1 more threads\n",
            "INFO - 08:11:15: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 08:11:15: EPOCH - 27 : training on 523700 raw words (199503 effective words) took 2.7s, 72740 effective words/s\n",
            "INFO - 08:11:17: EPOCH 28 - PROGRESS: at 37.40% examples, 74840 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 08:11:18: EPOCH 28 - PROGRESS: at 78.53% examples, 75109 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 08:11:18: worker thread finished; awaiting finish of 2 more threads\n",
            "INFO - 08:11:18: worker thread finished; awaiting finish of 1 more threads\n",
            "INFO - 08:11:18: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 08:11:18: EPOCH - 28 : training on 523700 raw words (199304 effective words) took 2.6s, 76441 effective words/s\n",
            "INFO - 08:11:19: EPOCH 29 - PROGRESS: at 37.40% examples, 73752 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 08:11:20: EPOCH 29 - PROGRESS: at 74.71% examples, 72030 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 08:11:21: worker thread finished; awaiting finish of 2 more threads\n",
            "INFO - 08:11:21: worker thread finished; awaiting finish of 1 more threads\n",
            "INFO - 08:11:21: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 08:11:21: EPOCH - 29 : training on 523700 raw words (199329 effective words) took 2.7s, 74058 effective words/s\n",
            "INFO - 08:11:22: EPOCH 30 - PROGRESS: at 37.40% examples, 73571 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 08:11:23: EPOCH 30 - PROGRESS: at 76.60% examples, 74780 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 08:11:23: worker thread finished; awaiting finish of 2 more threads\n",
            "INFO - 08:11:23: worker thread finished; awaiting finish of 1 more threads\n",
            "INFO - 08:11:23: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 08:11:23: EPOCH - 30 : training on 523700 raw words (198902 effective words) took 2.6s, 76258 effective words/s\n",
            "INFO - 08:11:23: training on a 15711000 raw words (5975803 effective words) took 80.0s, 74669 effective words/s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time to train the model: 1.33 mins\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocUWKRDaPWgP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bab1fd92-7f5a-4751-87b5-450234deb33f"
      },
      "source": [
        "w2v_model.init_sims(replace=True)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO - 08:12:43: precomputing L2-norms of word weight vectors\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQI_MsI2P9Zd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "222302c8-9073-4404-9f47-16fd546ea326"
      },
      "source": [
        "w2v_model.wv.most_similar(positive=[\"homer_simpson\"])"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('pleased', 0.7633680701255798),\n",
              " ('congratulation', 0.7631620168685913),\n",
              " ('recent', 0.7597476243972778),\n",
              " ('governor', 0.7590283155441284),\n",
              " ('easily', 0.7576010823249817),\n",
              " ('council', 0.7408592700958252),\n",
              " ('hutz', 0.7347520589828491),\n",
              " ('robert', 0.7318389415740967),\n",
              " ('simon', 0.7308964729309082),\n",
              " ('committee', 0.7258784770965576)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEL7y6dAQCmS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "3541cdd2-9e50-46fd-a6c2-5867446cd6f0"
      },
      "source": [
        "w2v_model.wv.most_similar(positive=[\"homer\"])"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('marge', 0.7794296145439148),\n",
              " ('rude', 0.7755630016326904),\n",
              " ('bongo', 0.7644156813621521),\n",
              " ('snuggle', 0.7563874125480652),\n",
              " ('wife', 0.7388522624969482),\n",
              " ('gee', 0.7364005446434021),\n",
              " ('sorry', 0.7309480309486389),\n",
              " ('worry', 0.727098822593689),\n",
              " ('hammock', 0.7240004539489746),\n",
              " ('sweetheart', 0.7224789261817932)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKCErCNjQHA4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "ef841266-471f-47a1-cce8-74ef19720bdf"
      },
      "source": [
        "w2v_model.wv.most_similar(positive=[\"dr_hibbert\"])"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('convince', 0.8436061143875122),\n",
              " ('rabbi', 0.831490159034729),\n",
              " ('hearing', 0.8250008821487427),\n",
              " ('catholic', 0.7999840378761292),\n",
              " ('bitch', 0.7841911911964417),\n",
              " ('rude', 0.7727895379066467),\n",
              " ('attract', 0.7696405649185181),\n",
              " ('stress', 0.7687424421310425),\n",
              " ('technically', 0.7678347229957581),\n",
              " ('crisis', 0.7677313089370728)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qS4U6KQQLLX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "395796c7-e0c4-4859-e344-0a9995868669"
      },
      "source": [
        "w2v_model.wv.most_similar(positive=[\"bart\"])"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('lisa', 0.8431563377380371),\n",
              " ('surprised', 0.7916699051856995),\n",
              " ('homework', 0.7898970246315002),\n",
              " ('mom', 0.7895394563674927),\n",
              " ('convince', 0.7756944894790649),\n",
              " ('upset', 0.7745141386985779),\n",
              " ('mom_dad', 0.77126145362854),\n",
              " ('strangle', 0.7669622898101807),\n",
              " ('substitute', 0.7586274147033691),\n",
              " ('typical', 0.7566486597061157)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7TWfu31QbuL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "efb7ae4c-61f5-4078-dab7-58cbc7c0e665"
      },
      "source": [
        "from gensim.models import Phrases\n",
        "documents = [\"the mayor of new york was there\", \"machine learning can be useful sometimes\",\"new york mayor was present\",\"My name is yashu gupta\"]\n",
        "\n",
        "sentence_stream = [doc.split(\" \") for doc in documents]\n",
        "bigram = Phrases(sentence_stream, min_count=1, threshold=2)\n",
        "sent = [u'the', u'mayor', u'of', u'new', u'york', u'was', u'there']\n",
        "print(bigram[sent])"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO - 08:40:58: collecting all words and their counts\n",
            "INFO - 08:40:58: PROGRESS: at sentence #0, processed 0 words and 0 word types\n",
            "INFO - 08:40:58: collected 37 word types from a corpus of 23 words (unigram + bigrams) and 4 sentences\n",
            "INFO - 08:40:58: using 37 counts as vocab in Phrases<0 vocab, min_count=1, threshold=2, max_vocab_size=40000000>\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "['the', 'mayor', 'of', 'new_york', 'was', 'there']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
            "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RaG5B_1MVxPq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}